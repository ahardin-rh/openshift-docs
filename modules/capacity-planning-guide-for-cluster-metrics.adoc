// Module included in the following assemblies:
//
// scalability_and_performance/scaling-cluster-metrics-components.adoc

[id='capacity_planning_for_cluster_metrics']
= Capacity planning for cluster metrics

In tests performed with 210 and 990 {product-title} nodes, where 10500 pods
and 11000 pods were monitored respectively, the Cassandra database grew at the
speed shown in the table below:

.Cassandra Database storage requirements based on number of nodes/pods in the cluster
[options="header"]
|===
|Number of Nodes |Number of Pods |Cassandra Storage growth speed |Cassandra storage growth per day |Cassandra storage growth per week

|210
|10500
|500 MB per hour
|15 GB
|75 GB

|990
|11000
|1 GB per hour
|30 GB
|210 GB
|===

In the above calculation, approximately 20 percent of the expected size was added as
overhead to ensure that the storage requirements do not exceed calculated value.

If the `METRICS_DURATION` and `METRICS_RESOLUTION` values are kept at the
default (`7` days and `15` seconds respectively), it is safe to plan Cassandra
storage size requirements for week, as in the values above.

[WARNING]
====
Because {product-title} metrics uses the Cassandra database as a datastore for
metrics data, if `USE_PERSISTENT_STORAGE=true` is set during the metrics set up
process, `PV` will be on top in the network storage, with NFS as the default.
However, using network storage in combination with Cassandra is not recommended.

If you use a Cassandra database as a datastore for metrics data, see the
link:http://cassandra.apache.org/doc/latest/operating/hardware.html#disks[Cassandra
documentation] for their recommendations.
====
